{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeOWYCIqJgyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BEKmvvJJk6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_df = pd.read_csv('ca_labeled.csv', index_col=[0])\n",
        "ny_df = pd.read_csv('ny_labeled.csv', index_col=[0])\n",
        "tx_df = pd.read_csv('tx_labeled.csv', index_col=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9uIVxtbhKK5",
        "colab_type": "code",
        "outputId": "372a0be2-c24d-446c-a088-1f5022397eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'Only some businesses can open this wk. Yes t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'#California nurse just confirmed they are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'I really wish phase 2 included hair and nail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>b'#California loosens rules for visitor in hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>b'This is welcome news for #California. Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   values                                         tweet_text\n",
              "0      -1  b'Only some businesses can open this wk. Yes t...\n",
              "1      -1  b'#California nurse just confirmed they are al...\n",
              "2      -1  b'I really wish phase 2 included hair and nail...\n",
              "3       0  b'#California loosens rules for visitor in hos...\n",
              "4       1  b'This is welcome news for #California. Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bxN_-l3gnag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def features(value):\n",
        "  if(value == -1):\n",
        "    value = 'neg'\n",
        "    return value\n",
        "  elif(value == 1):\n",
        "    value = 'pos'\n",
        "    return value\n",
        "  else:\n",
        "    value = 'neu'\n",
        "    return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtdDnsoshQCt",
        "colab_type": "code",
        "outputId": "7f6611d1-30fd-4576-f48f-092cb0fd0906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df['values'] = ca_df['values'].apply(features)\n",
        "ny_df['values'] = ny_df['values'].apply(features)\n",
        "tx_df['values'] = tx_df['values'].apply(features)\n",
        "\n",
        "ca_df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'Only some businesses can open this wk. Yes t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'#California nurse just confirmed they are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'I really wish phase 2 included hair and nail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>b'#California loosens rules for visitor in hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>b'This is welcome news for #California. Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  b'Only some businesses can open this wk. Yes t...\n",
              "1    neg  b'#California nurse just confirmed they are al...\n",
              "2    neg  b'I really wish phase 2 included hair and nail...\n",
              "3    neu  b'#California loosens rules for visitor in hos...\n",
              "4    pos  b'This is welcome news for #California. Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g3Iczj0ieuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk \n",
        "\n",
        "from nltk import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "def tokenize_tweets(tweet):\n",
        "  tweet = tweet_tokenizer.tokenize(tweet)\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "___H6a6ritMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_df['tweet_text'] = ca_df['tweet_text'].apply(tokenize_tweets)\n",
        "ny_df['tweet_text'] = ny_df['tweet_text'].apply(tokenize_tweets)\n",
        "tx_df['tweet_text'] = tx_df['tweet_text'].apply(tokenize_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEY6eqAhM9Z0",
        "colab_type": "code",
        "outputId": "0e578edc-75c2-4a03-8049-047c658f85b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, some, businesses, can, open, this, wk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, just, confirmed, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, for, visit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, is, welcome, news, for, #California, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, some, businesses, can, open, this, wk...\n",
              "1    neg  [b, ', #California, nurse, just, confirmed, th...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, for, visit...\n",
              "4    pos  [b'This, is, welcome, news, for, #California, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZZJ_yxCji5Y",
        "colab_type": "code",
        "outputId": "a26b7c8b-15b0-4514-ca90-70ca61315edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(tweet):\n",
        "  tweet = [n for n in tweet if not n in stop_words]\n",
        "  return tweet"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EYP9wWqkB2o",
        "colab_type": "code",
        "outputId": "64210ad4-810f-4bc7-dfc4-50261a7fdaa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df['tweet_text'] = ca_df['tweet_text'].apply(remove_stopwords)\n",
        "ny_df['tweet_text'] = ny_df['tweet_text'].apply(remove_stopwords)\n",
        "tx_df['tweet_text'] = tx_df['tweet_text'].apply(remove_stopwords)\n",
        "\n",
        "ca_df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, businesses, open, wk, ., Yes, wanna, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, confirmed, saying, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, visitor, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, welcome, news, #California, ., Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, businesses, open, wk, ., Yes, wanna, ...\n",
              "1    neg  [b, ', #California, nurse, confirmed, saying, ...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, visitor, h...\n",
              "4    pos  [b'This, welcome, news, #California, ., Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO6vME7CKEZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def cleanTxt(text):\n",
        "    text = re.sub('@[A-Za-z0â€“9]+', '', text)\n",
        "    text = re.sub('#', '', text)\n",
        "    text = re.sub('RT[\\s]+', '', text)\n",
        "    text = re.sub('https?:\\/\\/\\S+', '', text)\n",
        "    text = re.sub('/', '', text)\n",
        "    text = text.replace('\\\\', '')\n",
        "    \n",
        "    text = re.sub('x97', '', text)\n",
        "    text = re.sub('xa3', '', text)\n",
        "    text = re.sub('x98People', '', text)\n",
        "    text = re.sub('x98', '', text)\n",
        "    text = re.sub('xa0', '', text)\n",
        "    text = re.sub('x94and', '', text)\n",
        "    text = re.sub('x96', '', text)\n",
        "    text = re.sub('x99s', '', text)\n",
        "    text = re.sub('x91', '', text)\n",
        "    text = re.sub('x8a', '', text)\n",
        "    text = re.sub('xba', '', text)\n",
        "    text = re.sub('x9b', '', text)\n",
        "    text = re.sub('xbc', '', text)\n",
        "    text = re.sub('x92', '', text)\n",
        "    text = re.sub('xbf', '', text)\n",
        "    text = re.sub('x89https', '', text)\n",
        "    text = re.sub('x94By', '', text)\n",
        "    text = re.sub('x8f', '', text)\n",
        "    text = re.sub('xb8', '', text)\n",
        "    text = re.sub('xa4', '', text)\n",
        "    text = re.sub('xa5', '', text)\n",
        "    text = re.sub('x87', '', text)\n",
        "    text = re.sub('xa5WOW', '', text)\n",
        "    text = re.sub('x94', '', text)\n",
        "    text = re.sub('x95', '', text)\n",
        "    text = re.sub('xb3', '', text)\n",
        "    text = re.sub('x89', '', text)\n",
        "    text = re.sub('x9f', '', text)\n",
        "    text = re.sub('x9ccoronavirus', '', text)\n",
        "    text = re.sub('xbd', '', text)\n",
        "    text = re.sub('x9cnatural', '', text)\n",
        "    text = re.sub('x9cmusic', '', text)\n",
        "    text = re.sub('xa9', '', text)\n",
        "    text = re.sub('x82', '', text)\n",
        "    text = re.sub('xc2', '', text)\n",
        "    text = re.sub('x83', '', text)\n",
        "    text = re.sub('x99all', '', text)\n",
        "    text = re.sub('xb1al', '', text)\n",
        "    text = re.sub('x9cessential', '', text)\n",
        "    text = re.sub('x9cEveryone', '', text)\n",
        "    text = re.sub('x8e', '', text)\n",
        "    text = re.sub('x98Reopen', '', text)\n",
        "    text = re.sub('xe3', '', text)\n",
        "    text = re.sub('xa2', '', text)\n",
        "    text = re.sub('x80', '', text)\n",
        "    text = re.sub('x99m', '', text)\n",
        "    text = re.sub('x90', '', text)\n",
        "    text = re.sub('x9e', '', text)\n",
        "    text = re.sub('x99', '', text)\n",
        "    text = re.sub('xb9', '', text)\n",
        "    text = re.sub('xbb', '', text)\n",
        "    text = re.sub('x99re', '', text)\n",
        "    text = re.sub('xa3https', '', text)\n",
        "    text = re.sub('x98Burden', '', text)\n",
        "    text = re.sub('x9cprogressives', '', text)\n",
        "    text = re.sub('xb1d19', '', text)\n",
        "    text = re.sub('xaa', '', text)\n",
        "    text = re.sub('x86', '', text)\n",
        "    text = re.sub('x8c', '', text)\n",
        "    text = re.sub('x93', '', text)\n",
        "    text = re.sub('x9d', '', text)\n",
        "    text = re.sub('x88', '', text)\n",
        "    text = re.sub('x99t', '', text)\n",
        "    text = re.sub('xef', '', text)\n",
        "    text = re.sub('xf0', '', text)\n",
        "    text = re.sub('xa7', '', text)\n",
        "    text = re.sub('xb7', '', text)\n",
        "    text = re.sub('x9cThe', '', text)\n",
        "    text = re.sub('x9c', '', text)\n",
        "    text = re.sub('x99mon', '', text)\n",
        "    text = re.sub('x99d', '', text)\n",
        "    text = re.sub('xb5', '', text)\n",
        "    text = re.sub('xc3', '', text)\n",
        "    text = re.sub('xe2', '', text)\n",
        "    text = re.sub('x8d', '', text)\n",
        "    text = re.sub('xb0', '', text)\n",
        "    text = re.sub('xa6it', '', text)\n",
        "    text = re.sub('x98CA', '', text)\n",
        "    text = re.sub('xc4', '', text)\n",
        "    text = re.sub('xa8', '', text)\n",
        "    text = re.sub('x9cthe', '', text)\n",
        "    text = re.sub('x99ve', '', text)\n",
        "    text = re.sub('x81', '', text)\n",
        "    text = re.sub('x8fTake', '', text)\n",
        "    text = re.sub('x85', '', text)\n",
        "    text = re.sub('x99S', '', text)\n",
        "    text = re.sub('xb8OPEN', '', text)\n",
        "    text = re.sub('xa6', '', text)\n",
        "    text = re.sub('x8fUplifting', '', text)\n",
        "    text = re.sub('xb8TYRANT', '', text)\n",
        "    text = re.sub('xac', '', text)\n",
        "    text = re.sub('x99ll', '', text)\n",
        "    text = re.sub('x9cfix', '', text)\n",
        "    text = re.sub('x98declared', '', text)\n",
        "    text = re.sub('xa1', '', text)\n",
        "    text = re.sub('x98fix', '', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg_KQzRAMHkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ca_df['tweet_text'])):\n",
        "  for n in range(len(ca_df['tweet_text'][i])):\n",
        "    ca_df['tweet_text'][i][n] = cleanTxt(ca_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH4lVJ9POKfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ny_df['tweet_text'])):\n",
        "  for n in range(len(ny_df['tweet_text'][i])):\n",
        "    ny_df['tweet_text'][i][n] = cleanTxt(ny_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UznA_j2cONbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(tx_df['tweet_text'])):\n",
        "  for n in range(len(tx_df['tweet_text'][i])):\n",
        "    tx_df['tweet_text'][i][n] = cleanTxt(tx_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEjvp9ZiNY0v",
        "colab_type": "code",
        "outputId": "cbe50033-7876-4482-b23e-0506d4f72840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, businesses, open, wk, ., Yes, wanna, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', California, nurse, confirmed, saying, v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', California, loosens, rules, visitor, ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, welcome, news, California, ., Policy,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, businesses, open, wk, ., Yes, wanna, ...\n",
              "1    neg  [b, ', California, nurse, confirmed, saying, v...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', California, loosens, rules, visitor, ho...\n",
              "4    pos  [b'This, welcome, news, California, ., Policy,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI-J0MYjMRqt",
        "colab_type": "code",
        "outputId": "e836c251-827f-4682-df58-da088551dc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tweets(tweet):\n",
        "  tweet = lemmatizer.lemmatize(tweet)\n",
        "  return tweet"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK4VHWoCMfOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ca_df['tweet_text'])):\n",
        "  for n in range(len(ca_df['tweet_text'][i])):\n",
        "    ca_df['tweet_text'][i][n] = lemmatize_tweets(ca_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_df['tweet_text'])):\n",
        "  for n in range(len(ny_df['tweet_text'][i])):\n",
        "    ny_df['tweet_text'][i][n] = lemmatize_tweets(ny_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_df['tweet_text'])):\n",
        "  for n in range(len(tx_df['tweet_text'][i])):\n",
        "    tx_df['tweet_text'][i][n] = lemmatize_tweets(tx_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pXWDXenKQKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "dataset = []\n",
        "\n",
        "ca_dataset = []\n",
        "for row in ca_df.itertuples(index = False):\n",
        "    ca_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "ny_dataset = []\n",
        "for row in ny_df.itertuples(index = False):\n",
        "    ny_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "tx_dataset = []\n",
        "for row in tx_df.itertuples(index = False):\n",
        "    tx_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "dataset = ca_dataset + ny_dataset + tx_dataset\n",
        "\n",
        "\n",
        "random.shuffle(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vysq2FxNKR5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words = []\n",
        "for i in range(len(ca_df.index)):\n",
        "    for w in ca_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "        \n",
        "for i in range(len(ny_df.index)):\n",
        "    for w in ny_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "        \n",
        "for i in range(len(tx_df.index)):\n",
        "    for w in tx_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez7MNpdyKTw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_features = [item[0] for item in all_words.most_common(300)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvDg1d6FKVjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_features(tweet):\n",
        "    words = set(tweet)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    \n",
        "    return features\n",
        "\n",
        "feature_sets = [(find_features(tweet), value) for (tweet, value) in dataset]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg8OVjU1KXCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = feature_sets[:1200]\n",
        "testing_set = feature_sets[1200:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGlYBUMxKYST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYIABlFaKZze",
        "colab_type": "code",
        "outputId": "57a0830e-5443-4990-aea1-f4d35063a81d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(testing_set), len(training_set))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300 1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RNsNt8TKbiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for i in range(len(testing_set)):\n",
        "    results.append(classifier.classify(testing_set[i][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lXa85JTKc34",
        "colab_type": "code",
        "outputId": "5041a309-d637-4dd1-8896-3cba7ad8ad9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(results))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igomLi-4KeTS",
        "colab_type": "code",
        "outputId": "242e162c-53b4-4b87-b856-f32422c733a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "error = 0\n",
        "for i in range(len(results)):\n",
        "    print(results[i], ' : ', testing_set[i][1])\n",
        "    if(results[i] != testing_set[i][1]):\n",
        "        error += 1\n",
        "\n",
        "error = (error/300) * 100\n",
        "        \n",
        "print(\"Error: \" + str(error) + \"%\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "pos  :  neg\n",
            "pos  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "pos  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  pos\n",
            "neu  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neg\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "pos  :  pos\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neg\n",
            "neg  :  neu\n",
            "pos  :  pos\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "neg  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neu  :  pos\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neg\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "Error: 35.66666666666667%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxFy2fH_e201",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_new_df = pd.read_csv('COVID_California_current.csv')\n",
        "ny_new_df = pd.read_csv('COVID19_newyork_current.csv')\n",
        "tx_new_df = pd.read_csv('COVID19_texas_current.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcFRJqj5RJOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "ca_new_df['tweet_text'] = ca_new_df['tweet_text'].apply(tokenize_tweets)\n",
        "ny_new_df['tweet_text'] = ny_new_df['tweet_text'].apply(tokenize_tweets)\n",
        "tx_new_df['tweet_text'] = tx_new_df['tweet_text'].apply(tokenize_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkAaNmZfRhhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ca_new_df['tweet_text'] = ca_new_df['tweet_text'].apply(remove_stopwords)\n",
        "ny_new_df['tweet_text'] = ny_new_df['tweet_text'].apply(remove_stopwords)\n",
        "tx_new_df['tweet_text'] = tx_new_df['tweet_text'].apply(remove_stopwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgar4hEyRogy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  for n in range(len(ca_new_df['tweet_text'][i])):\n",
        "    ca_new_df['tweet_text'][i][n] = cleanTxt(ca_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  for n in range(len(ny_new_df['tweet_text'][i])):\n",
        "    ny_new_df['tweet_text'][i][n] = cleanTxt(ny_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  for n in range(len(tx_new_df['tweet_text'][i])):\n",
        "    tx_new_df['tweet_text'][i][n] = cleanTxt(tx_new_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie44vvaISRmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  for n in range(len(ca_new_df['tweet_text'][i])):\n",
        "    ca_new_df['tweet_text'][i][n] = lemmatize_tweets(ca_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  for n in range(len(ny_new_df['tweet_text'][i])):\n",
        "    ny_new_df['tweet_text'][i][n] = lemmatize_tweets(ny_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  for n in range(len(tx_new_df['tweet_text'][i])):\n",
        "    tx_new_df['tweet_text'][i][n] = lemmatize_tweets(tx_new_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdpvZetRTSxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "all_words_new = []\n",
        "for i in range(len(ca_new_df.index)):\n",
        "    for w in ca_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "        \n",
        "for i in range(len(ny_new_df.index)):\n",
        "    for w in ny_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "        \n",
        "for i in range(len(tx_new_df.index)):\n",
        "    for w in tx_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "\n",
        "\n",
        "all_words_new = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpsXy6cSTk71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_features_new = [item[0] for item in all_words_new.most_common(300)]\n",
        "\n",
        "def find_features_new(tweet):\n",
        "    words = set(tweet)\n",
        "    features = {}\n",
        "    for w in word_features_new:\n",
        "        features[w] = (w in words)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvjeYQ8UTw26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "results_new_ca = []\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  feature = find_features_new(ca_new_df['tweet_text'][i])\n",
        "  results_new_ca.append(classifier.classify(feature))\n",
        "\n",
        "results_new_ny = []\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  feature = find_features_new(ny_new_df['tweet_text'][i])\n",
        "  results_new_ny.append(classifier.classify(feature))\n",
        "\n",
        "results_new_tx = []\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  feature = find_features_new(tx_new_df['tweet_text'][i])\n",
        "  results_new_tx.append(classifier.classify(feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m47Jb-QlVv7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_percent(results):\n",
        "  neg = 0\n",
        "  neu = 0\n",
        "  pos = 0\n",
        "  for i in results:\n",
        "    if(i == 'neg'):\n",
        "      neg += 1\n",
        "    elif(i == 'neu'):\n",
        "      neu += 1\n",
        "    else:\n",
        "      pos += 1\n",
        "\n",
        "  print(\"Pos:\", str(pos / len(results) * 100) + \"%\")\n",
        "  print(\"Neg:\", str(neg / len(results) * 100) + \"%\")\n",
        "  print(\"Neu:\", str(neu / len(results) * 100) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FGZngPAWx9t",
        "colab_type": "code",
        "outputId": "9e4bfa6a-cb2b-4c27-8ca3-42d4abdc18d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_ca)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 5.544147843942506%\n",
            "Neg: 21.560574948665298%\n",
            "Neu: 72.8952772073922%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmUcB4U7W6JI",
        "colab_type": "code",
        "outputId": "fdb3a851-cb93-4f9f-a9c6-b8ac456d1a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_ny)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 7.142857142857142%\n",
            "Neg: 18.377976190476193%\n",
            "Neu: 74.47916666666666%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIWeaZJua-g1",
        "colab_type": "code",
        "outputId": "0a089943-fdbe-4e46-f203-2cec6b22af0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_tx)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 8.665511265164644%\n",
            "Neg: 29.462738301559792%\n",
            "Neu: 61.871750433275565%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}